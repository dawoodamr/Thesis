\chapter{Conclusion}
We have discussed that the AGM framework introduces a reasonable set of rules that can be followed to reach rationality in building belief systems. However, we used a different formalism to express knowledge and perform contraction throughout this study than the one the AGM framework uses. This formalism, which is $\mathcal{EL}$, belongs to a family called Description Logic (DL). $\mathcal{EL}$ is one of the simple members of the DL family, and, as the rest of the DLs, uses concepts and roles as the building blocks of the knowledge base. We only showed how to perform contraction on TBoxes, and not ABoxes. We then discussed some basic approaches to contraction and introduced a general algorithm that can accommodate the use of different heuristics to seek optimality. 

We introduced a restricted contraction algorithm that uses graphs and solves contraction as a network flow problem. The graph approach is restricted in the sense that it can be used only in certain cases where inference in the TBox involves only the transitive property of the subsumption relation. We showed how the approach is sound and complete (only in the restricted cases) by showing that it follows most of the AGM postulates for contraction. We also discussed three heuristics, two of which are based on the semantics of the subsumption hierarchy of $\mathcal{EL}$, which are Localization and Specificity. We showed also how the greedy approach for contraction can be used.

The bottleneck for the contraction algorithms we discussed is actually generating all the kernels of a specific belief. The pinpointing algorithm we use for this purpose can sometimes take exponential number of steps with respect to the size of the TBox. Other than that, all the algorithms we discussed take polynomial time to run. 

TBox kernel contraction can be implemented to find the smallest set of beliefs to be removed in polynomial time using the graph approach. The graph approach works only when the inference involves only the subsumption relationship, not the existential quantification. The complexity of the algorithm is the same as the network flow algorithm complexity as it uses the concept of minimum cut to compute the kernels.

Specificity is also one of the main contributions of this study. The $\mathcal{EL}$ description logic sets up a hierarchical relationship between concepts that reflects a specificity relationship. A concept can be said to be more (or less) specific compared to another concept based on the subsumption relationship in the TBox. This inspires the solution we adopted in removing knowledge about more specific concepts before considering more general ones.

One addition that could be done in the future is to give an algorithm that contracts explicit knowledge in the ABox, not just the TBox. Also, the use of $\mathcal{EL}$ was very important to finding polynomial time contraction algorithms. One other contribution could be to attempt to use other, more expressive, versions of DL and investigate if this results in higher order contraction than polynomial. Another intriguing question is: what advantage would using a more expressive DL give, and will it be worth it if contraction algorithms get harder and more complicated? 